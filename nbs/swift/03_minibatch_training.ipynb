{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/jmd/workspace/ml/fastai/nbs/swift/FastaiNotebook_02a_why_sqrt5\")\n",
      "\t\tFastaiNotebook_02a_why_sqrt5\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpd2s7kkzb/swift-install\n",
      "/home/jmd/swift/usr/bin/swift-build: /home/jmd/anaconda3/lib/libcurl.so.4: no version information available (required by /home/jmd/swift/usr/lib/swift/linux/libFoundationNetworking.so)\n",
      "[1/3] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[2/4] Merging module jupyterInstalledPackages\n",
      "[3/3] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(path: \"$cwd/FastaiNotebook_02a_why_sqrt5\")' FastaiNotebook_02a_why_sqrt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import Path\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastaiNotebook_02a_why_sqrt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public typealias TI = Tensor<Int32>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var (xTrain,yTrain,xValid,yValid) = loadMNIST(path: Path.home/\".fastai\"/\"data\"/\"mnist_tst\", flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "let trainMean = xTrain.mean()\n",
    "let trainStd  = xTrain.standardDeviation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = normalize(xTrain, mean: trainMean, std: trainStd)\n",
    "xValid = normalize(xValid, mean: trainMean, std: trainStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 784 10\r\n"
     ]
    }
   ],
   "source": [
    "let (n,m) = (xTrain.shape[0],xTrain.shape[1])\n",
    "let c = yTrain.max().scalarized()+1\n",
    "print(n,m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct MyModel: Layer {\n",
    "    public var layer1: FADense<Float>\n",
    "    public var layer2: FADense<Float>\n",
    "    \n",
    "    public init(nIn: Int, nHid: Int, nOut: Int){\n",
    "        layer1 = FADense(nIn, nHid, activation: relu)\n",
    "        layer2 = FADense(nHid, nOut)\n",
    "    }\n",
    "    \n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: TF) -> TF {\n",
    "        return input.sequenced(through: layer1, layer2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "let pred = model(xTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    let exped = exp(activations) \n",
    "    return log(exped / exped.sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 4]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain[0..<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â–¿ 3 elements\n",
       "  - .0 : -3.6093674\n",
       "  - .1 : -3.1815867\n",
       "  - .2 : -2.280293\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(smPred[0][5],smPred[1][0],smPred[2][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "func nll<Scalar>(_ input: Tensor<Scalar>, _ target :TI) -> Tensor<Scalar> \n",
    "    where Scalar:TensorFlowFloatingPoint{\n",
    "        let idx: TI = _Raw.range(start: Tensor(0), limit: Tensor(numericCast(target.shape[0])), delta: Tensor(1))\n",
    "        let indices = _Raw.concat(concatDim: Tensor(1), [idx.expandingShape(at: 1), target.expandingShape(at: 1)])\n",
    "        let losses = _Raw.gatherNd(params: input, indices: indices)\n",
    "        return -losses.mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5352411\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 1.3821034900000007 ms,   min: 0.708999 ms,   max: 3.365624 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ let _ = nll(smPred, yTrain) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    return activations - log(exp(activations).sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5352411\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â–¿ [60000, 1]\n",
       "  â–¿ dimensions : 2 elements\n",
       "    - 0 : 60000\n",
       "    - 1 : 1\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smPred.max(alongAxes: -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSumExp<Scalar>(_ x: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    let m = x.max(alongAxes: -1)\n",
    "    return m + log(exp(x-m).sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    return activations - logSumExp(activations)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5352411\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5352411\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let loss = softmaxCrossEntropy(logits: pred, labels: yTrain)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 1.2442005399999998 ms,   min: 0.482056 ms,   max: 6.137875 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ _ = nll(logSoftmax(pred), yTrain)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.053128540000000016 ms,   min: 0.052441 ms,   max: 0.060195 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ _ = softmaxCrossEntropy(logits: pred, labels: yTrain)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public func accuracy(_ output: TF, _ target: TI) -> TF{\n",
    "    let corrects = TF(output.argmax(squeezingAxis: 1) .== target)\n",
    "    return corrects.mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09791667\r\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(pred, yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26924807,   0.7771155,   1.5648208, -0.03286986,  0.06529951, -0.88017595,    0.882473,\r\n",
      " -0.00849247,  -0.4475536,  0.09719473] [64, 10]\r\n"
     ]
    }
   ],
   "source": [
    "let bs=64                     // batch size\n",
    "let xb = xTrain[0..<bs]       // a mini-batch from x\n",
    "let preds = model(xb)         // predictions\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "let yb = yTrain[0..<bs]\n",
    "let loss = softmaxCrossEntropy(logits: preds, labels: yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078125\r\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "let lr:Float = 0.5   // learning rate\n",
    "let epochs = 1       // how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (loss, grads) = valueWithGradient(at: model) { model -> TF in\n",
    "    let preds = model(xb)\n",
    "    return softmaxCrossEntropy(logits: preds, labels: yb)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs {\n",
    "    for i in 0 ..< (n-1)/bs {\n",
    "        let startIdx = i * bs\n",
    "        let endIdx = startIdx + bs\n",
    "        let xb = xTrain[startIdx..<endIdx]\n",
    "        let yb = yTrain[startIdx..<endIdx]\n",
    "        let (loss, grads) = valueWithGradient(at: model) {\n",
    "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
    "        }\n",
    "        model.layer1.weight -= lr * grads.layer1.weight\n",
    "        model.layer1.bias   -= lr * grads.layer1.bias\n",
    "        model.layer2.weight -= lr * grads.layer2.weight\n",
    "        model.layer2.bias   -= lr * grads.layer2.bias\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8957\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let preds = model(xValid)\n",
    "accuracy(preds, yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs {\n",
    "    for i in 0 ..< (n-1)/bs {\n",
    "        let startIdx = i * bs\n",
    "        let endIdx = startIdx + bs\n",
    "        let xb = xTrain[startIdx..<endIdx]\n",
    "        let yb = yTrain[startIdx..<endIdx]\n",
    "        let (loss, grads) = valueWithGradient(at: model) {\n",
    "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
    "        }\n",
    "        model.move(along: grads.scaled(by: -lr))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "let optimizer = SGD(for: model, learningRate: lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public func batchedRanges(start:Int, end:Int, bs:Int) -> UnfoldSequence<Range<Int>,Int>\n",
    "{\n",
    "  return sequence(state: start) { (batchStart) -> Range<Int>? in\n",
    "    let remaining = end - batchStart\n",
    "    guard remaining > 0 else { return nil}\n",
    "    let currentBs = min(bs,remaining)\n",
    "    let batchEnd = batchStart.advanced(by: currentBs)\n",
    "    defer {  batchStart = batchEnd  }\n",
    "    return batchStart ..< batchEnd\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs{\n",
    "    for b in batchedRanges(start: 0, end: n, bs: bs) {\n",
    "        let (xb,yb) = (xTrain[b],yTrain[b])\n",
    "        let (loss, grads) = valueWithGradient(at: model) {\n",
    "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
    "        }\n",
    "        optimizer.update(&model, along: grads)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public struct DataBatch<Inputs: Differentiable & TensorGroup, Labels: TensorGroup>: TensorGroup {\n",
    "    public var xb: Inputs\n",
    "    public var yb: Labels\n",
    "    \n",
    "    public init(xb: Inputs, yb: Labels){ (self.xb,self.yb) = (xb,yb) }\n",
    "    \n",
    "    public var _tensorHandles: [_AnyTensorHandle] {\n",
    "        xb._tensorHandles + yb._tensorHandles\n",
    "    }\n",
    "    \n",
    "    public init<C: RandomAccessCollection>(_handles: C) where C.Element: _AnyTensorHandle {\n",
    "        let xStart = _handles.startIndex\n",
    "        let xEnd = _handles.index(\n",
    "            xStart, offsetBy: Int(Inputs._tensorHandleCount))\n",
    "        self.xb = Inputs.init(_handles: _handles[xStart..<xEnd])\n",
    "        self.yb = Labels.init(_handles: _handles[xEnd..<_handles.endIndex])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "let trainDs = Dataset(elements:DataBatch(xb:xTrain, yb:yTrain)).batched(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1...epochs{\n",
    "    for batch in trainDs {\n",
    "        let (loss, grads) = valueWithGradient(at: model) {\n",
    "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
    "        }\n",
    "        optimizer.update(&model, along: grads)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func train<Opt: Optimizer, Label:TensorGroup>(\n",
    "    _ model: inout Opt.Model,\n",
    "    on ds: Dataset<DataBatch<Opt.Model.Input, Label>>,\n",
    "    using opt: inout Opt,\n",
    "    lossFunc: @escaping @differentiable (Opt.Model.Output, @noDerivative Label) -> Tensor<Opt.Scalar>\n",
    ") where Opt.Model: Layer,\n",
    "        Opt.Model.Input: TensorGroup,\n",
    "        Opt.Scalar: TensorFlowFloatingPoint\n",
    "{\n",
    "    for batch in ds {\n",
    "        let (loss, ð›model) = valueWithGradient(at: model) {\n",
    "            lossFunc($0(batch.xb), batch.yb)\n",
    "        }\n",
    "        opt.update(&model, along: ð›model)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))\n",
    "var optimizer = SGD(for: model, learningRate: lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "@differentiable(wrt: logits)\n",
    "public func crossEntropy(_ logits: TF, _ labels: TI) -> TF {\n",
    "    return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(&model, on: trainDs, using: &optimizer, lossFunc: crossEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let preds = model(xValid)\n",
    "accuracy(preds, yValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\r\n"
     ]
    }
   ],
   "source": [
    "import NotebookExport\n",
    "let exporter = NotebookExport(Path.cwd/\"03_minibatch_training.ipynb\")\n",
    "print(exporter.export(usingPrefix: \"FastaiNotebook_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
